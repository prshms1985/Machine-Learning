{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "np.random.seed(47)\n",
    "\n",
    "#reviews = pd.read_csv('./socialmedia-disaster-tweets-DFE.csv')\n",
    "#print reviews.head()\n",
    "#print reviews.tail()\n",
    "reviews = pd.read_csv('socialmedia-disaster-tweets-DFE.csv')[['text','choose_one']]\n",
    "reviews.columns = ['tweet','sentiment']\n",
    "reviews = reviews[(reviews['sentiment'] == 'Relevant') | (reviews['sentiment'] == 'Not Relevant')]\n",
    "reviews = reviews.reset_index(drop=True)\n",
    "#reviews.head()\n",
    "reviews.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor(\"</a>This :) is :( a test :-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews['tweet'] = reviews['tweet'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "reviews = reviews.reindex(np.random.permutation(reviews.index))\n",
    "\n",
    "print reviews.head()\n",
    "print reviews.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews.groupby('sentiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews['length'] = reviews['tweet'].map(lambda text: len(text))\n",
    "print reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.length.plot(bins=20, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print list(reviews.tweet[reviews.length < 60].index)\n",
    "print list(reviews.tweet[reviews.length < 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reviews.hist(column='length', by='sentiment', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(tweet):\n",
    "    tweet = unicode(tweet, 'utf8')  # convert bytes into proper unicode\n",
    "    return TextBlob(tweet).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews.tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews.tweet.head().apply(split_into_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TextBlob(\"hello world, how is it going?\").tags  # list of (word, POS) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop = stop + [u'a',u'b',u'c',u'd',u'e',u'f',u'g',u'h',u'i',u'j',u'k',u'l',u'm',u'n',u'o',u'p',u'q',u'r',u's',u't',u'v',u'w',u'x',u'y',u'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(tweet):\n",
    "    tweet = unicode(tweet, 'utf8').lower()\n",
    "    words = TextBlob(tweet).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words if word not in stop]\n",
    "\n",
    "reviews.tweet.head().apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(reviews['tweet'])\n",
    "print len(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review4 = reviews['tweet'][7000]\n",
    "print review4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bow4 = bow_transformer.transform([review4])\n",
    "print bow4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "reviews_bow = bow_transformer.transform(reviews['tweet'])\n",
    "print 'sparse matrix shape:', reviews_bow.shape\n",
    "print 'number of non-zeros:', reviews_bow.nnz\n",
    "print 'sparsity: %.2f%%' % (100.0 * reviews_bow.nnz / (reviews_bow.shape[0] * reviews_bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews_bow_train = reviews_bow[:8000]\n",
    "reviews_bow_test = reviews_bow[8000:]\n",
    "reviews_sentiment_train = reviews['sentiment'][:8000]\n",
    "reviews_sentiment_test = reviews['sentiment'][8000:]\n",
    "\n",
    "print reviews_bow_train.shape\n",
    "print reviews_bow_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%time review_sentiment = MultinomialNB().fit(reviews_bow_train, reviews_sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print 'predicted:', review_sentiment.predict(bow4)[0]\n",
    "print 'expected:', reviews.sentiment[7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = review_sentiment.predict(reviews_bow_test)\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print 'accuracy', accuracy_score(reviews_sentiment_test, predictions)\n",
    "print 'confusion matrix\\n', confusion_matrix(reviews_sentiment_test, predictions)\n",
    "print '(row=expected, col=predicted)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print classification_report(reviews_sentiment_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(new_review): \n",
    "    new_sample = bow_transformer.transform([new_review])\n",
    "    print new_review, np.around(review_sentiment.predict_proba(new_sample), decimals=5),\"\\n\"\n",
    "\n",
    "predict_review('Car. disaster. Major. damage. to. property.')\n",
    "predict_review('storm. ugly. . bad. Best! horrible. terrible. loss. cannot. Powerful. swift. vacate. Incredible. isolated.')\n",
    "predict_review('Okay. Great.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_review(' Cat stuck in a tree.')\n",
    "predict_review('Car accident. Major damage to property.')\n",
    "predict_review('I ate a sandwich last night.')\n",
    "predict_review('Somehow, Mr. Dreyfuss maintains his sound comic timing even when Frank Oz''s antic direction calls for hand-waving hysteria.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
